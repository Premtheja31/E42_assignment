{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "942def8a",
      "metadata": {
        "id": "942def8a"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.stem import PorterStemmer\n",
        "import collections\n",
        "import spacy\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "UuxHGJIkTM-f"
      },
      "id": "UuxHGJIkTM-f",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "468a583e",
      "metadata": {
        "id": "468a583e"
      },
      "outputs": [],
      "source": [
        "stemmer=PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "8dc5d59a",
      "metadata": {
        "id": "8dc5d59a"
      },
      "outputs": [],
      "source": [
        "lemmatizer=WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Merging of two dictionaries with different keys**"
      ],
      "metadata": {
        "id": "TJ3hBPjh-4fa"
      },
      "id": "TJ3hBPjh-4fa"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "6ac5cc49",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ac5cc49",
        "outputId": "a6deca05-4672-4586-e6d7-fb803d55a5bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6}\n"
          ]
        }
      ],
      "source": [
        "def merge_dictionaries(d1,d2):\n",
        "    dummy=d1\n",
        "    dummy.update(d2)\n",
        "    return dummy\n",
        "\n",
        "d1={\"a\":1,\"b\":2,\"c\":3}\n",
        "d2={\"d\":4,\"e\":5,\"f\":6}\n",
        "\n",
        "print(merge_dictionaries(d1,d2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Given a corpus of verbs in a list , check if the present tense, past tense or continuous tense etc of the word exists in a sentence.**"
      ],
      "metadata": {
        "id": "NoGgOCal-0VX"
      },
      "id": "NoGgOCal-0VX"
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_of_verbs=[ \"run\" , \"Go\",\"come\",\"walk\",\"play\",\"rain\"]\n",
        "\n",
        "def finding_tenses(sentence,verbs=corpus_of_verbs):\n",
        "  doc = nlp(sentence)\n",
        "  for token in doc:\n",
        "    if token.pos_ == \"VERB\":\n",
        "        if \"VBZ\" in token.tag_:\n",
        "            print(f\"{token.text} is in the present tense.\")\n",
        "        elif \"VBP\" in token.tag_:\n",
        "            print(f\"{token.text} is in the present Continuous tense.\")\n",
        "        elif \"VBD\" in token.tag_:\n",
        "            print(f\"{token.text} is in the past tense.\")\n",
        "        elif \"VBG\" in token.tag_:\n",
        "            print(f\"{token.text} is in the present Participle tense.\")\n",
        "        elif \"VBG\" in token.tag_ and \"VBD\" in token.tag_:\n",
        "            print(f\"{token.text} is in the past continuous tense.\")\n",
        "        else:\n",
        "          print(\"Unknown Tense\")\n",
        "\n"
      ],
      "metadata": {
        "id": "tGg2kRyrRWES"
      },
      "id": "tGg2kRyrRWES",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#I am eating lunch while my friend is studying\"\n",
        "#while playing it is raining\n",
        "finding_tenses(input(\"enter sentences : \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrAd6lxDWiyC",
        "outputId": "6c09ed28-c401-47f5-feee-ce2a8520930c"
      },
      "id": "OrAd6lxDWiyC",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter sentences : while playing it is raining\n",
            "playing is in the present Participle tense.\n",
            "raining is in the present Participle tense.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. create a list of n-grams from a given sentence from 1 gram to the highest gram.**"
      ],
      "metadata": {
        "id": "gcxZmOhD-vH3"
      },
      "id": "gcxZmOhD-vH3"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "2ee88748",
      "metadata": {
        "id": "2ee88748"
      },
      "outputs": [],
      "source": [
        "def ngram_to_list(sentence):\n",
        "    print()\n",
        "    review=re.sub(\"[^a-zA-z]\",\" \",sentence)\n",
        "    review=review.lower()\n",
        "    review=review.split()\n",
        "    review=[lemmatizer.lemmatize(w) for w in review]\n",
        "    review=\" \".join(review)\n",
        "    print(review)\n",
        "    print()\n",
        "    count_is=len(review.split())\n",
        "    print(\"the highest ngram is\",count_is)\n",
        "    print()\n",
        "    train_set=[]\n",
        "    train_set.append(review)\n",
        "    cv=CountVectorizer(binary=True,ngram_range=(1,count_is))\n",
        "    X=cv.fit_transform(train_set)\n",
        "    list_ngrams=list(cv.vocabulary_)\n",
        "    print(\"the list of all the ngrams are\")\n",
        "    print()\n",
        "    print(list_ngrams)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPkUzHbu10_f",
        "outputId": "f2a1c934-d561-43f6-abd6-a5fb41b88845"
      },
      "id": "aPkUzHbu10_f",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "9d2749bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d2749bd",
        "outputId": "e01d8d1d-018c-40d7-d331-9cf3219e91ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter the sentence : hi how are you doing out there\n",
            "\n",
            "hi how are you doing out there\n",
            "\n",
            "the highest ngram is 7\n",
            "\n",
            "the list of all the ngrams are\n",
            "\n",
            "['hi', 'how', 'are', 'you', 'doing', 'out', 'there', 'hi how', 'how are', 'are you', 'you doing', 'doing out', 'out there', 'hi how are', 'how are you', 'are you doing', 'you doing out', 'doing out there', 'hi how are you', 'how are you doing', 'are you doing out', 'you doing out there', 'hi how are you doing', 'how are you doing out', 'are you doing out there', 'hi how are you doing out', 'how are you doing out there', 'hi how are you doing out there']\n"
          ]
        }
      ],
      "source": [
        "#hi how are you doing out there\n",
        "ngram_to_list(input(\"enter the sentence : \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Create a script to flatten a dictionary of multiple levels and then access any key within the given dictionary.**"
      ],
      "metadata": {
        "id": "zf9xnX8E-pnX"
      },
      "id": "zf9xnX8E-pnX"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "aae04008",
      "metadata": {
        "id": "aae04008"
      },
      "outputs": [],
      "source": [
        "def flatten(d, parent_key='', sep='.'):\n",
        "    items = []\n",
        "    for k, v in d.items():\n",
        "        new_key = parent_key + sep + k if parent_key else k\n",
        "        if isinstance(v, collections.MutableMapping):\n",
        "            items.extend(flatten(v, new_key, sep=sep).items())\n",
        "        else:\n",
        "            items.append((new_key, v))\n",
        "    return dict(items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "16fa2040",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16fa2040",
        "outputId": "50b8b8ad-153b-4e58-9ad5-2791630e49e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the flattened dictionary\n",
            "\n",
            "{'a': 1, 'c.a': 2, 'c.b.x': 5, 'c.b.y': 10, 'd': [1, 2, 3]}\n"
          ]
        }
      ],
      "source": [
        "d={'a': 1,'c': {'a': 2,'b': {'x': 5,'y' : 10}},'d': [1, 2, 3]}\n",
        "print(\"the flattened dictionary\")\n",
        "print()\n",
        "flattened_dict=flatten(d)\n",
        "print(flattened_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "b9358c6d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9358c6d",
        "outputId": "1a8eda71-78c7-41d5-9f45-5f81123216e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter key : c.b.y\n",
            "\n",
            "key: c.b.y and its value: 10\n"
          ]
        }
      ],
      "source": [
        "key=input(\"enter key : \")\n",
        "print()\n",
        "print(\"key:\",key,\"and its value:\",flattened_dict[key])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Write a script to find similarity match between 2 sentences.**"
      ],
      "metadata": {
        "id": "Kx0BJxgp-gaV"
      },
      "id": "Kx0BJxgp-gaV"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "1bcd65cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bcd65cd",
        "outputId": "ca0c0db5-1fcf-4ae7-de43-b8abd9db7490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter sentence 1: varshith and sanjeev are good friends\n",
            "\n",
            "enter sentence 2: varshith and sanjeev play together\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-66-e3cbcee1d8f0>:9: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity_score=first_sentence.similarity(second_sentence)\n"
          ]
        }
      ],
      "source": [
        "sentence_1=input(\"enter sentence 1: \")\n",
        "#varshith and sanjeev are good friends\n",
        "print()\n",
        "sentence_2=input(\"enter sentence 2: \")\n",
        "#varshith and sanjeev play together\n",
        "print()\n",
        "first_sentence=nlp(sentence_1)\n",
        "second_sentence=nlp(sentence_2)\n",
        "similarity_score=first_sentence.similarity(second_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"the similarity score between the two sentences are\",similarity_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91vmRJvg3Pdj",
        "outputId": "42f11acc-9519-43ff-8e00-3d3900ce4b4a"
      },
      "id": "91vmRJvg3Pdj",
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the similarity score between the two sentences are 0.627581738917148\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}